{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47337546",
   "metadata": {},
   "source": [
    "# Plug-and-Play Image Restoration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450402ce",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/generativemodelingmva/generativemodelingmva.github.io/blob/main/tp2324/tp8_pnp.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88703323",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "This practical session is dedicated to the implementation of plug-and-play algorithms with pre-learned denoisers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93afa4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.fft import fft2, ifft2, fftshift, ifftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import time    \n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "pi = torch.pi\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "!pip install bm3d\n",
    "# !pip install deepinv\n",
    "# or last version of deepinv:\n",
    "!pip install git+https://github.com/deepinv/deepinv.git#egg=deepinv\n",
    "import deepinv as dinv\n",
    "\n",
    "# Uncomment these two lines to download the files for this session\n",
    "!wget https://perso.telecom-paristech.fr/aleclaire/mva/tp8.zip\n",
    "!unzip tp8.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f666bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(u):\n",
    "    return 0.2989 * u[:,:,0] + 0.5870 * u[:,:,1] + 0.1140 * u[:,:,2]\n",
    "\n",
    "def str2(chars):\n",
    "    return \"{:.2f}\".format(chars)\n",
    "\n",
    "def psnr(uref,ut,M=1):\n",
    "    rmse = np.sqrt(np.mean((np.array(uref.cpu())-np.array(ut.cpu()))**2))\n",
    "    return 20*np.log10(M/rmse)\n",
    "\n",
    "def tensor2im(x):\n",
    "    return x.detach().cpu().permute(2,3,1,0).squeeze().clip(0,1)\n",
    "\n",
    "# viewimage\n",
    "import tempfile\n",
    "import IPython\n",
    "from skimage.transform import rescale\n",
    "\n",
    "def viewimage(im, normalize=True,vmin=0,vmax=1,z=2,order=0,titre='',displayfilename=False):\n",
    "    # By default, values are scaled with black=0 and white=1\n",
    "    # In order to adapt the dynamics to the image, enter vmin and vmax as None\n",
    "    im = im.detach().cpu().permute(2,3,1,0).squeeze()\n",
    "    imin= np.array(im).astype(np.float32)\n",
    "    channel_axis = 2 if len(im.shape)>2 else None\n",
    "    imin = rescale(imin, z, order=order, channel_axis=channel_axis)\n",
    "    if normalize:\n",
    "        if vmin is None:\n",
    "            vmin = imin.min()\n",
    "        if vmax is None:\n",
    "            vmax = imin.max()\n",
    "        imin-=vmin\n",
    "        if np.abs(vmax-vmin)>1e-10:\n",
    "            imin = (imin.clip(vmin,vmax)-vmin)/(vmax-vmin)\n",
    "        else:\n",
    "            imin = vmin\n",
    "    else:\n",
    "        imin=imin.clip(0,255)/255 \n",
    "    imin=(imin*255).astype(np.uint8)\n",
    "    filename=tempfile.mktemp(titre+'.png')\n",
    "    if displayfilename:\n",
    "        print (filename)\n",
    "    plt.imsave(filename, imin, cmap='gray')\n",
    "    IPython.display.display(IPython.display.Image(filename))\n",
    "\n",
    "\n",
    "# alternative viewimage if the other one does not work:\n",
    "def Viewimage(im,dpi=100,cmap='gray'):\n",
    "    plt.figure(dpi=dpi)\n",
    "    if cmap is None:\n",
    "        plt.imshow(np.array(im))\n",
    "    else:\n",
    "        plt.imshow(np.array(im),cmap=cmap)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3baf5",
   "metadata": {},
   "source": [
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307d160",
   "metadata": {},
   "source": [
    "# Exercise 1: Plug-and-Play Image Deblurring (with periodic convolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360daab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image\n",
    "x0 = torch.tensor(plt.imread('im/simpson512crop.png'),device=device)\n",
    "# x0 = torch.tensor(plt.imread('im/parrots.png'),device=device); x0 = x0[100:356,370:626,:]\n",
    "# x0 = torch.tensor(plt.imread('im/marge2.png'),device=device)\n",
    "# x0 = torch.tensor(plt.imread('im/simpson512.png'),device=device)\n",
    "M,N,C = x0.shape\n",
    "# Permute dimensions to fit tensor convention\n",
    "x0 = x0.permute(2,0,1).unsqueeze(0)\n",
    "\n",
    "viewimage(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533cf4d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load a blur kernel\n",
    "kt = torch.tensor(np.loadtxt('kernels/kernel8.txt'))\n",
    "# kt = np.loadtxt('kernels/levin7.txt')\n",
    "(m,n) = kt.shape\n",
    "\n",
    "plt.imshow(kt)\n",
    "plt.title('Blur kernel')\n",
    "plt.show()\n",
    "\n",
    "# Embed the kernel in a MxNx3 image, and put center at pixel (0,0)\n",
    "k = torch.zeros((M,N),device=device)\n",
    "k[0:m,0:n] = kt/torch.sum(kt)\n",
    "k = torch.roll(k,(-int(m/2),-int(n/2)),(0,1))\n",
    "#k = k[:,:,None].repeat(1,1,3)\n",
    "#k = k.permute(2,0,1).unsqueeze(0)\n",
    "k = k[None,None,:,:]\n",
    "fk = fft2(k)\n",
    "\n",
    "viewimage(fftshift(k),vmin=None,vmax=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae0fa5a",
   "metadata": {},
   "source": [
    "## Test a pre-learned denoiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422d176",
   "metadata": {},
   "source": [
    "Compute a noisy image\n",
    "$$ y = x_0 + \\xi $$\n",
    "where $\\xi \\sim \\mathcal{N}(0,\\nu^2 \\mathsf{Id})$.\n",
    "Denoise the image $y$ by using a pre-learned denoiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448cdb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nu = 2/255 # 0.15\n",
    "y = x0 + nu*torch.randn_like(x0,device=device)\n",
    "\n",
    "# Load the DRUNet denoiser\n",
    "# https://deepinv.github.io/deepinv/stubs/deepinv.models.DRUNet.html\n",
    "# D = dinv.models.DRUNet(pretrained='ckpts/drunet_color.pth').to(device)\n",
    "\n",
    "# Load the BM3D denoiser\n",
    "# https://deepinv.github.io/deepinv/stubs/deepinv.models.BM3D.html\n",
    "# D = dinv.models.BM3D().to(device)\n",
    "\n",
    "# Load the DnCNN denoiser (WARNING: the proposed weights are only trained for noise level sigma = 2/255)\n",
    "# https://deepinv.github.io/deepinv/stubs/deepinv.models.DnCNN.html\n",
    "D = dinv.models.DnCNN(pretrained='ckpts/dncnn_sigma2_color.pth').to(device)\n",
    "# D = dinv.models.DnCNN(pretrained='ckpts/dncnn_sigma2_lipschitz_color.pth').to(device)\n",
    "\n",
    "# TV denoiser (only in last version of deepinv)\n",
    "# Dtv = dinv.models.TVDenoiser().to(device)\n",
    "# def D(x,sigma):\n",
    "#   return Dtv(x,ths=2*sigma**2)\n",
    "\n",
    "# noisy image\n",
    "print('PSNR(x0,y) = %.2f'%psnr(x0,y))\n",
    "viewimage(y)\n",
    "# denoise image\n",
    "Dy = D(y,sigma=nu)\n",
    "print('PSNR(x0,Dy) = %.2f'%psnr(x0,Dy))\n",
    "viewimage(Dy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48bcce3",
   "metadata": {},
   "source": [
    "## Image deblurring with PnP-PGD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3c8763",
   "metadata": {},
   "source": [
    "Implement the forward model\n",
    "$$ y = A(x_0) + \\xi $$\n",
    "where $\\xi \\sim \\mathcal{N}(0,\\nu^2 \\mathsf{Id})$.\n",
    "Write functions implementing the operator $A(x)$ and the data-fidelity term $f(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = .01  # noise level\n",
    "torch.manual_seed(1)  # fix random seed for reproducibility\n",
    "\n",
    "# Define corresponding operator and data-fidelity\n",
    "def A(x):\n",
    "    return ### TODO ###\n",
    "\n",
    "def f(x):\n",
    "    return ### TODO ###\n",
    "\n",
    "# Draw a sample of the direct model for image deblurring (apply blur and add Gaussian noise)\n",
    "### TODO ###\n",
    "\n",
    "viewimage(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c2925",
   "metadata": {},
   "source": [
    "In this question, we will perform deblurring with the PnP-PGD algorithm \n",
    "$$ x_{k+1} = D_\\sigma \\circ (\\operatorname{Id} - \\tau \\nabla f) (x_k) $$\n",
    "where $f(x) = \\frac{1}{2\\nu^2} \\|Ax-y\\|_2^2$ is the data-fidelity term.\n",
    "\n",
    "Recall that $\\tau$ should be $< \\frac{2}{L}$ where $L$ is the Lipschitz constant of $\\nabla f$.\n",
    "\n",
    "Complete the following cell progressively, in order to address the following points:\n",
    "1. Implement the PnP-PGD algorithm, and display the deblurred image.\n",
    "2. Track the evolution of the PSNR.\n",
    "3. Track the evolution of the residual $r_n = \\frac{\\|x_n - x_{n-1}\\|}{\\|x_0\\|}$.\n",
    "4. Try to adjust the parameter $\\tau$ (gradient step size / strength of data-fidelity).\n",
    "5. Try to adjust the parameter $s$ (strength of the denoiser).\n",
    "6. Track the evolution of $v_n = \\frac{\\|D_\\sigma(a_n) - D_\\sigma(b_{n})\\|}{\\|a_n - b_n\\|}$ (which lower bounds the Lipschitz constant of $D_\\sigma$). <br/>\n",
    "  You may choose sequences $(a_n), (b_n)$ that depend on the last iterates without additional evaluations of $D_\\sigma$.\n",
    "7. Store the PSNR/Residual tables and compare with several denoisers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7964c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tau = ###\n",
    "s = 2*nu  # strength of the denoiser (that is, sigma)\n",
    "\n",
    "# initialize with blurry image\n",
    "x = y.clone()\n",
    "\n",
    "psnrtab = []  # to store psnr\n",
    "rtab = []     # to store residual\n",
    "vtab = []     # to store denoiser variations\n",
    "\n",
    "niter = 100\n",
    "t0 = time.time()\n",
    "print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(0,niter,0,psnr(x0,y)))\n",
    "\n",
    "for it in range(niter):\n",
    "    \n",
    "    ### TODO ###\n",
    "    \n",
    "    if (it+1)%10==0:\n",
    "        print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(it+1,niter,time.time()-t0,psnrt))\n",
    "        viewimage(x)\n",
    "        \n",
    "xpgd = x   # save for later comparisons\n",
    "\n",
    "plt.plot(psnrtab)\n",
    "plt.title('PSNR')\n",
    "plt.show()\n",
    "\n",
    "# plt.semilogy(rtab)\n",
    "# plt.title('Residual Norm')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(vtab)\n",
    "# plt.title('Denoiser Variations')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ff500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tables obtained with various denoisers for later comparisons\n",
    "\n",
    "# psnrtabtmp = psnrtab.copy()\n",
    "# rtabtmp = rtab.copy()\n",
    "# vtabtmp = vtab.copy()\n",
    "# rtab_bm3d = rtab.copy()\n",
    "# psnrtab_bm3d = psnrtab.copy()\n",
    "# vtab_bm3d = vtab.copy()\n",
    "# rtab_drunet = rtab.copy()\n",
    "# psnrtab_drunet = psnrtab.copy()\n",
    "# vtab_drunet = vtab.copy()\n",
    "# rtab_dncnn = rtab.copy()\n",
    "# psnrtab_dncnn = psnrtab.copy()\n",
    "# vtab_dncnn = vtab.copy()\n",
    "# rtab_dncnnlip = rtab.copy()\n",
    "# psnrtab_dncnnlip = psnrtab.copy()\n",
    "# vtab_dncnnlip = vtab.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d78ae4",
   "metadata": {},
   "source": [
    "Compare with explicit regularizations (Tychonov, smoothTV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f034f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Deblurring with Tychonov Regularization\n",
    "def tych_deblur(y,k,lam=0.01):\n",
    "    _,_,M,N = y.shape\n",
    "    xi = torch.arange(M)\n",
    "    ind = (xi>M/2)\n",
    "    xi[ind] = xi[ind]-M\n",
    "    zeta = torch.arange(N)\n",
    "    ind = (zeta>N/2)\n",
    "    zeta[ind] = zeta[ind]-N\n",
    "    Xi,Zeta = torch.meshgrid(xi,zeta,indexing='ij')\n",
    "    Xi = Xi[None,None,:,:].to(device)\n",
    "    Zeta = Zeta[None,None,:,:].to(device)\n",
    "    fh = torch.conj(fk)/(torch.abs(fk)**2 + 8 * lam * (torch.sin(pi*Xi/M)**2 + torch.sin(pi*Zeta/N)**2))\n",
    "    return ifft2(fft2(y)*fh).real\n",
    "\n",
    "xtych = tych_deblur(y,k)\n",
    "\n",
    "# Smooth TV regularization\n",
    "def stv_deblur(A,y,xinit,niter=1000,lam=0.002,ep=0.01,lr=None):\n",
    "    if lr is None:\n",
    "        lr = 1.9/(1+lam*8/ep)\n",
    "    x = xinit.clone().requires_grad_(True)\n",
    "    optim = torch.optim.SGD([x], lr=lr)\n",
    "    losslist = []\n",
    "    for it in range(niter):\n",
    "        d1 = torch.roll(x,-1,2) - x\n",
    "        d2 = torch.roll(x,-1,3) - x\n",
    "        reg = torch.sum(torch.sqrt(ep**2+d1**2+d2**2))\n",
    "        loss = torch.sum((A(x)-y)**2) + lam*reg\n",
    "        losslist.append(loss.item())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    return x.detach(),losslist\n",
    "\n",
    "xtv,losslist = stv_deblur(A,y,y.clone())\n",
    "# plt.plot(losslist)\n",
    "# plt.show()\n",
    "\n",
    "# Display the results\n",
    "print('PSNR(x0,xtych) = %.2f'%psnr(x0,xtych))\n",
    "viewimage(xtych)\n",
    "print('PSNR(x0,xtv) = %.2f'%psnr(x0,xtv))\n",
    "viewimage(xtv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203a79e",
   "metadata": {},
   "source": [
    "Compare results obtained with PnP-PGD and with explicit regularizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8efe6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=180)\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(tensor2im(x0), cmap='gray')\n",
    "plt.title('Original',fontsize=8)\n",
    "# plt.imshow(tensor2im(y), cmap='gray')\n",
    "# plt.title('Degraded \\n PSNR='+str2(psnr(x0,y)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(tensor2im(xtych), cmap='gray')\n",
    "plt.title('Tychonov \\n PSNR='+str2(psnr(x0,xtych)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(tensor2im(xtv), cmap='gray')\n",
    "plt.title('SmoothTV \\n PSNR='+str2(psnr(x0,xtv)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(tensor2im(xpgd), cmap='gray')\n",
    "plt.title('PnP-PGD \\n PSNR='+str2(psnr(x0,xpgd)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc8d81",
   "metadata": {},
   "source": [
    "Compare Residual Norms, PSNR, and Denoiser variations for various denoisers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c5385d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.semilogy(rtab_dncnn,label='DnCNN')\n",
    "plt.semilogy(rtab_dncnnlip,label='DnCNNLip')\n",
    "plt.semilogy(rtab_drunet,label='DRUNet')\n",
    "plt.semilogy(rtab_bm3d,label='BM3D')\n",
    "plt.legend()\n",
    "plt.title('Residual Norm')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(psnrtab_dncnn,label='DnCNN')\n",
    "plt.plot(psnrtab_dncnnlip,label='DnCNNLip')\n",
    "plt.plot(psnrtab_drunet,label='DRUNet')\n",
    "plt.plot(psnrtab_bm3d,label='BM3D')\n",
    "plt.plot([psnr(x0,xtv)]*niter,label='smoothTV')\n",
    "plt.plot([psnr(x0,xtych)]*niter,label='Tychonov')\n",
    "plt.legend()\n",
    "plt.title('PSNR')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(vtab_dncnn,label='DnCNN')\n",
    "plt.plot(vtab_dncnnlip,label='DnCNNLip')\n",
    "plt.plot(vtab_drunet,label='DRUNet')\n",
    "plt.plot(vtab_bm3d,label='BM3D')\n",
    "plt.legend()\n",
    "plt.title('Denoiser Variations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dbb0ec",
   "metadata": {},
   "source": [
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacb760d",
   "metadata": {},
   "source": [
    "## Image deblurring with PnP-HQS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f97cd50",
   "metadata": {},
   "source": [
    "Implement the proximal operator of the data-fidelity term:\n",
    "$$\\mathsf{Prox}_{\\tau f}(x) = \\left( \\frac{1}{\\nu^2} A^T A + \\frac{1}{\\tau} \\mathsf{Id} \\right)^{-1} \\left( \\frac{1}{\\nu^2} A^T y + \\frac{1}{\\tau} x \\right) .$$\n",
    "Since $A$ is here a periodic convolution, this calculation can be done in Fourier domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68911bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxf(x,tau):\n",
    "    ### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c215975",
   "metadata": {},
   "source": [
    "Implement the PnP-HQS algorithm \n",
    "$$ x_{k+1} = D_\\sigma \\circ \\mathsf{Prox}_{\\tau f} (x_k) .$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23e12d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae2d90f",
   "metadata": {},
   "source": [
    "## Image deblurring with PnP-DRS\n",
    "\n",
    "Implement the PnP-DRS algorithm \n",
    "$$ x_{k+1} = \\left(\\frac{1}{2} \\mathsf{Id} + \\frac{1}{2} (2 D_\\sigma - \\mathsf{Id}) \\circ (2\\mathsf{Prox}_{\\tau f}-\\mathsf{Id})\\right) (x_k) .$$\n",
    "Recall that the solution of the inverse problem is obtained after one proximal step\n",
    "$$ \\tilde{x}_k = \\mathsf{Prox}_{\\tau f} (x_k) .$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e845111",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8c1d7",
   "metadata": {},
   "source": [
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9801cd91",
   "metadata": {},
   "source": [
    "# Exercise 2: Image deblurring with non-periodic boundary conditions\n",
    "\n",
    "Implement a PnP algorithm that addresses image deblurring with non-periodic boundary conditions.\n",
    "\n",
    "You should adapt the codes written in the previous cells for this new forward model. We advise you to make a copy of the whole notebook and to make the adaptation in a separate file.\n",
    "\n",
    "Which PnP splitting method can you use for this particular setting?\n",
    "\n",
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90bf44",
   "metadata": {},
   "source": [
    "# Exercise 3: Image super-resolution\n",
    "\n",
    "Implement a PnP algorithm that addresses image deblurring with non-periodic boundary conditions.\n",
    "\n",
    "You should adapt the codes written in the previous cells for super-resolution. The forward model for super-resolution involves an anti-aliasing filter whose Fourier transform is given in the next cell.\n",
    "\n",
    "We advise you to make a copy of the whole notebook and to make the adaptation in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378aa337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the framework to address super-resolution with smoothed TV\n",
    "# For anti-aliasing, you may use the Butterworth filter of order n and cut-off frequency fc \n",
    "#   given below\n",
    "\n",
    "# fc is the cut-off frequency normalized in (0,1)\n",
    "def butterworth(M,N,fc=.5,order=5):\n",
    "    xi = torch.arange(M)\n",
    "    ind = (xi>M/2)\n",
    "    xi[ind] = xi[ind]-M\n",
    "    zeta = torch.arange(N)\n",
    "    ind = (zeta>N/2)\n",
    "    zeta[ind] = zeta[ind]-N\n",
    "    Xi,Zeta = torch.meshgrid(xi,zeta,indexing='ij')\n",
    "    Xi = Xi[None,None,:,:].to(device)\n",
    "    Zeta = Zeta[None,None,:,:].to(device)\n",
    "    bf1 = 1/torch.sqrt(1+(Xi/(M*fc/2))**(2*order))\n",
    "    bf2 = 1/torch.sqrt(1+(Zeta/(N*fc/2))**(2*order))\n",
    "    return bf1*bf2\n",
    "    \n",
    "bf = butterworth(M,N)\n",
    "viewimage(bf)\n",
    "\n",
    "# Use example:\n",
    "bf = butterworth(x0.shape[2],x0.shape[3],fc=.5)\n",
    "x0f = ifft2(bf*fft2(x0)).real\n",
    "\n",
    "viewimage(x0)\n",
    "viewimage(x0f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
