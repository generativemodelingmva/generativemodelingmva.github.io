{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88703323",
   "metadata": {},
   "source": [
    "# Plug-and-Play Image Restoration\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "In this practical session, we will implement **plug-and-play algorithms with the gradient-step denoiser**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93afa4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.fft import fft2, ifft2, fftshift, ifftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import time    \n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "pi = torch.pi\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "!pip install pytorch-lightning\n",
    "# !pip install bm3d\n",
    "# !pip install deepinv\n",
    "# or last version of deepinv:\n",
    "!pip install git+https://github.com/deepinv/deepinv.git#egg=deepinv\n",
    "import deepinv as dinv\n",
    "\n",
    "# Uncomment these two lines to download the files for this session\n",
    "!wget https://perso.telecom-paristech.fr/aleclaire/mva/tp9.zip\n",
    "!unzip tp9.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f666bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(u):\n",
    "    return 0.2989 * u[:,:,0] + 0.5870 * u[:,:,1] + 0.1140 * u[:,:,2]\n",
    "\n",
    "def str2(chars):\n",
    "    return \"{:.2f}\".format(chars)\n",
    "\n",
    "def psnr(uref,ut,M=1):\n",
    "    rmse = np.sqrt(np.mean((np.array(uref.cpu())-np.array(ut.cpu()))**2))\n",
    "    return 20*np.log10(M/rmse)\n",
    "\n",
    "def tensor2im(x):\n",
    "    return x.detach().cpu().permute(2,3,1,0).squeeze().clip(0,1)\n",
    "\n",
    "# viewimage\n",
    "import tempfile\n",
    "import IPython\n",
    "from skimage.transform import rescale\n",
    "\n",
    "def viewimage(im, normalize=True,vmin=0,vmax=1,z=2,order=0,titre='',displayfilename=False):\n",
    "    # By default, values are scaled with black=0 and white=1\n",
    "    # In order to adapt the dynamics to the image, enter vmin and vmax as None\n",
    "    im = im.detach().cpu().permute(2,3,1,0).squeeze()\n",
    "    imin= np.array(im).astype(np.float32)\n",
    "    channel_axis = 2 if len(im.shape)>2 else None\n",
    "    imin = rescale(imin, z, order=order, channel_axis=channel_axis)\n",
    "    if normalize:\n",
    "        if vmin is None:\n",
    "            vmin = imin.min()\n",
    "        if vmax is None:\n",
    "            vmax = imin.max()\n",
    "        imin-=vmin\n",
    "        if np.abs(vmax-vmin)>1e-10:\n",
    "            imin = (imin.clip(vmin,vmax)-vmin)/(vmax-vmin)\n",
    "        else:\n",
    "            imin = vmin\n",
    "    else:\n",
    "        imin=imin.clip(0,255)/255 \n",
    "    imin=(imin*255).astype(np.uint8)\n",
    "    filename=tempfile.mktemp(titre+'.png')\n",
    "    if displayfilename:\n",
    "        print (filename)\n",
    "    plt.imsave(filename, imin, cmap='gray')\n",
    "    IPython.display.display(IPython.display.Image(filename))\n",
    "\n",
    "\n",
    "# alternative viewimage if the other one does not work:\n",
    "def Viewimage(im,dpi=100,cmap='gray'):\n",
    "    plt.figure(dpi=dpi)\n",
    "    if cmap is None:\n",
    "        plt.imshow(np.array(im))\n",
    "    else:\n",
    "        plt.imshow(np.array(im),cmap=cmap)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b3baf5",
   "metadata": {},
   "source": [
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307d160",
   "metadata": {},
   "source": [
    "# Exercise 1: Plug-and-Play Image Deblurring (with periodic convolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bd562a",
   "metadata": {},
   "source": [
    "First, we load a clean image and a blur kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360daab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image\n",
    "x0 = torch.tensor(plt.imread('im/simpson512crop.png'),device=device)\n",
    "# x0 = torch.tensor(plt.imread('im/parrots.png'),device=device); x0 = x0[100:356,370:626,:]\n",
    "# x0 = torch.tensor(plt.imread('im/marge2.png'),device=device)\n",
    "# x0 = torch.tensor(plt.imread('im/simpson512.png'),device=device)\n",
    "M,N,C = x0.shape\n",
    "# Permute dimensions to fit tensor convention\n",
    "x0 = x0.permute(2,0,1).unsqueeze(0).contiguous()\n",
    "\n",
    "viewimage(x0)\n",
    "\n",
    "# Load a blur kernel\n",
    "kt = torch.tensor(np.loadtxt('kernels/kernel8.txt'))\n",
    "# kt = np.loadtxt('kernels/levin7.txt')\n",
    "(m,n) = kt.shape\n",
    "\n",
    "plt.imshow(kt)\n",
    "plt.title('Blur kernel')\n",
    "plt.show()\n",
    "\n",
    "# Embed the kernel in a MxNx3 image, and put center at pixel (0,0)\n",
    "k = torch.zeros((M,N),device=device)\n",
    "k[0:m,0:n] = kt/torch.sum(kt)\n",
    "k = torch.roll(k,(-int(m/2),-int(n/2)),(0,1))\n",
    "k = k[None,None,:,:]\n",
    "fk = fft2(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8ff05",
   "metadata": {},
   "source": [
    "## Forward Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3c8763",
   "metadata": {},
   "source": [
    "Implement the forward model\n",
    "$$ y = A(x_0) + \\xi $$\n",
    "where $\\xi \\sim \\mathcal{N}(0,\\nu^2 \\mathsf{Id})$.\n",
    "Write functions implementing the operator $A(x)$, the data-fidelity term $f(x)$, and its proximal operator $\\mathsf{Prox}_{\\tau f}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = .01  # noise level\n",
    "torch.manual_seed(1)  # fix random seed for reproducibility\n",
    "\n",
    "# Define corresponding operator and data-fidelity\n",
    "\n",
    "### TODO ####\n",
    "\n",
    "# Draw a sample of the direct model for image deblurring (apply blur and add Gaussian noise)\n",
    "### TODO ####\n",
    "\n",
    "viewimage(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a232a3",
   "metadata": {},
   "source": [
    "## Test the Gradient-Step Denoiser and the corresponding regularization\n",
    "\n",
    "In the following, we will use several algorithms to minimize\n",
    "$$F(x) = f(x) + \\lambda g_{\\sigma}(x)$$\n",
    "where $g_{\\sigma}$ is the regularization function linked to the gradient-step denoiser.\n",
    "\n",
    "The function $g_{\\sigma}$ is accessible through `D.potential`, and the corresponding gradient-step denoiser then writes\n",
    "$$ D_{\\sigma} = \\mathsf{Id} - \\nabla g_{\\sigma} .$$\n",
    "<br/><br/>\n",
    "\n",
    "In the following cell, test the gradient-step denoiser on a noisy image `xnoisy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the gradient-step denoiser\n",
    "D=dinv.models.GSDRUNet(pretrained='ckpts/GSDRUNet.ckpt', train=False).to(device)\n",
    "# D=dinv.models.GSDRUNet(pretrained='ckpts/Prox-DRUNet.ckpt', train=False).to(device)\n",
    "\n",
    "\n",
    "xnoisy = x0+nu*torch.randn_like(x0,device=device)\n",
    "x = xnoisy.clone().requires_grad_(True)\n",
    "px = D.potential(x,sigma=nu)\n",
    "grad = torch.autograd.grad(px,x)[0]\n",
    "\n",
    "Dx = xnoisy-grad\n",
    "\n",
    "viewimage(Dx)\n",
    "\n",
    "# # alternately, you can use\n",
    "# Dx = D(xnoisy,sigma=nu)\n",
    "# # but this causes a requires_grad problem on a previous version of deepinv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80139e48",
   "metadata": {},
   "source": [
    "## PnP-GD with Gradient-Step Denoiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71ab6d4",
   "metadata": {},
   "source": [
    "Implement the gradient descent algorithm \n",
    "$$ x_{k+1} = x_k - \\tau \\nabla F(x_k) .$$\n",
    "Along the iterations, track the function values $F(x_k)$, the PSNR and the residual norm $r_k = \\|x_{k}-x_{k-1}\\|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b652e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GSDRUNET\n",
    "# https://deepinv.github.io/deepinv/stubs/deepinv.models.GSDRUNet.html\n",
    "D=dinv.models.GSDRUNet(pretrained='ckpts/GSDRUNet.ckpt', train=False).to(device)\n",
    "\n",
    "tau = 2e-4\n",
    "s = 1.8*nu  # strength of the denoiser (sigma in the text)\n",
    "lam = 1600\n",
    "\n",
    "# Define the objective function\n",
    "def F(x, lam):\n",
    "    return ### TODO ###\n",
    "\n",
    "# initialize\n",
    "x = torch.clone(y).requires_grad_(True)\n",
    "normxinit = torch.linalg.vector_norm(x.detach())\n",
    "\n",
    "losstab = []\n",
    "psnrtab = []\n",
    "rtab = []\n",
    "niter = 100\n",
    "t0 = time.time()\n",
    "print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(0,niter,0,psnr(x0,y)))\n",
    "\n",
    "\n",
    "\n",
    "for it in range(niter):\n",
    "\n",
    "    ### TODO ###\n",
    "    \n",
    "    losstab.append(loss.item())\n",
    "    psnrtab.append(psnrt)\n",
    "    rtab.append(r.item())\n",
    "    \n",
    "    if (it+1)%10==0:\n",
    "        print('[%4d/%4d] [%.5f s] PSNR = %.2f, F(x) = %.6f, tau = %.6f'%(it+1,niter,time.time()-t0,psnrt,loss.item(),tau))\n",
    "        viewimage(x)\n",
    "\n",
    "        \n",
    "plt.plot(losstab)\n",
    "plt.title('F(x_k)')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(psnrtab)\n",
    "plt.title('PSNR')\n",
    "plt.show()\n",
    "\n",
    "plt.semilogy(rtab)\n",
    "plt.title('Residual Norm')\n",
    "plt.show()\n",
    "\n",
    "# save results\n",
    "x_gsgd = x.detach().clone()\n",
    "losstab_gsgd = losstab.copy()\n",
    "psnrtab_gsgd = psnrtab.copy()\n",
    "rtab_gsgd = rtab.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95611a37",
   "metadata": {},
   "source": [
    "## PnP-PGD with Gradient-Step Denoiser And Backtracking\n",
    "\n",
    "Implement the proximal gradient descent algorithm \n",
    "$$ x_{k+1} = \\mathsf{Prox}_{\\tau f}\\big(x_k - \\tau  \\lambda \\nabla g_{\\sigma}(x_k) \\big) .$$\n",
    "Along the iterations, track the function values $F(x_k)$, the PSNR and the residual norm $r_k = \\|x_{k}-x_{k-1}\\|$.\n",
    "\n",
    "Modify your code in order to include the backtracking procedure: at each iteration,\n",
    "$$ \\textbf{while} \\quad  F(x_k) - F(T_\\tau(x_k)) > \\frac{\\gamma}{\\tau} \\|T_\\tau(x_k) - x_k\\|^2 \\quad \\textbf{do} \\quad \\tau \\leftarrow \\eta \\tau .$$\n",
    "You may take $\\gamma = 0.4, \\eta = 0.9$.\n",
    "\n",
    "Modify your code so that the output image $\\tilde{x}_k$ (variable `xvisu`) is the one obtained before the last proximal step:\n",
    "$$ x_k = \\mathsf{Prox}_{\\tau f}(\\tilde{x}_k) .$$\n",
    "You may display `xvisu` instead of `x` and track PSNR with `xvisu`. (In order to improve visual quality, it is useful not to apply the last data-fidelity step which adds back some noise.) <br/>\n",
    "You may also display the value $F(\\tilde{x}_k)$ which corresponds to values obtained by the HQS algorithm\n",
    "$$ \\tilde{x}_{k+1} = D_\\sigma(\\mathsf{Prox}_{\\tau f}(\\tilde{x}_k))$$\n",
    "where $D_\\sigma = \\mathsf{Id} - \\nabla g_\\sigma$ is (by abuse) seen here as a proximal regularization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630e0a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GSDRUNET\n",
    "# https://deepinv.github.io/deepinv/stubs/deepinv.models.GSDRUNet.html\n",
    "D=dinv.models.GSDRUNet(pretrained='ckpts/GSDRUNet.ckpt', train=False).to(device)\n",
    "\n",
    "# Parameters\n",
    "tau = 2e-4\n",
    "s = 1.8*nu  # strength of the denoiser (sigma in the text)\n",
    "lam = 1600\n",
    "\n",
    "# initialize\n",
    "x = torch.clone(y).requires_grad_(True)\n",
    "normxinit = torch.linalg.vector_norm(x.detach())\n",
    "xvisuold = x.detach().clone()\n",
    "\n",
    "losstab = []\n",
    "psnrtab = []\n",
    "rtab = []\n",
    "# same tables for \\tilde{x} :\n",
    "losstab2 = []\n",
    "psnrtab2 = []\n",
    "rtab2 = []\n",
    "\n",
    "niter = 100\n",
    "t0 = time.time()\n",
    "print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(0,niter,0,psnr(x0,y)))\n",
    "\n",
    "for it in range(niter):\n",
    "\n",
    "    \n",
    "    ### TODO ###\n",
    "\n",
    "    if (it+1)%10==0:\n",
    "        # print('[%4d/%4d] [%.5f s] PSNR = %.2f, F(x) = %.6f, tau = %.6f'%(it+1,niter,time.time()-t0,psnrt2,Fxnew.item(),tau))\n",
    "        viewimage(xvisu)\n",
    "\n",
    "        \n",
    "plt.plot(losstab,label='PGD')\n",
    "plt.plot(losstab2,label='PGD2')\n",
    "plt.title('F(x_n)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(psnrtab,label='PGD')\n",
    "plt.plot(psnrtab2,label='PGD2')\n",
    "plt.title('PSNR')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.semilogy(rtab,label='PGD')\n",
    "plt.semilogy(rtab2,label='PGD2')\n",
    "plt.title('Residual Norm')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# save results\n",
    "x_gspgd = x.detach().clone()\n",
    "losstab_gspgd = losstab.copy()\n",
    "psnrtab_gspgd = psnrtab.copy()\n",
    "rtab_gspgd = rtab.copy()\n",
    "\n",
    "x_gspgd2 = xvisu.clone()\n",
    "losstab_gspgd2 = losstab2.copy()\n",
    "psnrtab_gspgd2 = psnrtab2.copy()\n",
    "rtab_gspgd2 = rtab2.copy()\n",
    "\n",
    "# # save results\n",
    "# tmp_x_gspgd = x.detach().clone()\n",
    "# tmp_losstab_gspgd = losstab.copy()\n",
    "# tmp_psnrtab_gspgd = psnrtab.copy()\n",
    "# tmp_rtab_gspgd = rtab.copy()\n",
    "\n",
    "# tmp_x_gspgd2 = xvisu.clone()\n",
    "# tmp_losstab_gspgd2 = losstab2.copy()\n",
    "# tmp_psnrtab_gspgd2 = psnrtab2.copy()\n",
    "# tmp_rtab_gspgd2 = rtab2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763d1d4f",
   "metadata": {},
   "source": [
    "## PGD with standard DRUNET denoiser\n",
    "\n",
    "Implement the PGD algorithm\n",
    "$$ x_{k+1} = D_\\sigma(x_k - \\tau \\nabla f(x_k)) $$\n",
    "by taking directly $D_\\sigma$ as the DRUNET (or GS-DRUNET) denoiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e6655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D = dinv.models.DRUNet(pretrained='ckpts/drunet_color.pth').to(device)\n",
    "# D = dinv.models.DnCNN(pretrained='ckpts/dncnn_sigma2_color.pth').to(device)\n",
    "# D = dinv.models.DnCNN(pretrained='ckpts/dncnn_sigma2_lipschitz_color.pth').to(device)\n",
    "\n",
    "tau = 1.9*nu**2\n",
    "s = 2*nu  # strength of the denoiser\n",
    "\n",
    "# tau = .1*nu**2\n",
    "# s= .1*nu   # make things diverge for DRUNet\n",
    "\n",
    "# initialize\n",
    "x = y.clone()\n",
    "normxinit = torch.linalg.vector_norm(x)\n",
    "\n",
    "psnrtab = []\n",
    "rtab = []\n",
    "niter = 1000\n",
    "t0 = time.time()\n",
    "print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(0,niter,0,psnr(x0,y)))\n",
    "for it in range(niter):\n",
    "    xt = x.clone().requires_grad_(True)\n",
    "    fx = f(xt)\n",
    "    grad = torch.autograd.grad(outputs=fx, inputs=xt)[0]\n",
    "    with torch.no_grad():\n",
    "        xnew = x-tau*grad\n",
    "        Dxnew = D(xnew,sigma=s)\n",
    "        x = Dxnew\n",
    "        xold = xnew.clone()\n",
    "        Dxold = Dxnew.clone()\n",
    "    psnrt = psnr(x0,x)\n",
    "    r = torch.linalg.vector_norm(xt.detach()-x)/normxinit\n",
    "    psnrtab.append(psnrt)\n",
    "    rtab.append(r.cpu())\n",
    "    \n",
    "    if (it+1)%10==0:\n",
    "        print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(it+1,niter,time.time()-t0,psnrt))\n",
    "        viewimage(x)\n",
    "    \n",
    "x_pgd = x.detach().clone()\n",
    "losstab_pgd = losstab.copy()\n",
    "psnrtab_pgd = psnrtab.copy()\n",
    "rtab_pgd = rtab.copy()\n",
    "\n",
    "plt.plot(psnrtab)\n",
    "plt.title('PSNR')\n",
    "plt.show()\n",
    "\n",
    "plt.semilogy(rtab)\n",
    "plt.title('Residual Norm')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(vtab)\n",
    "plt.title('Denoiser Variations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b618fb6",
   "metadata": {},
   "source": [
    "## PnP-PGD with Proximal Denoiser\n",
    "\n",
    "Now, we will consider the proximal gradient descent algorithm in the other way round:\n",
    "$$ \\begin{cases} z_{k+1} = x_k - \\frac{1}{\\lambda} \\nabla f(x_k) \\\\ x_{k+1} = D_{\\sigma} (z_{k+1}) \\end{cases} ,$$\n",
    "where $D_{\\sigma}$ is seen as a proximal operator.\n",
    "\n",
    "In order to have proper convergence, we will consider the proximal denoiser\n",
    "$$ D_\\sigma = \\mathsf{Id} - \\nabla g_{\\sigma} = \\mathsf{Prox}_{\\phi_\\sigma} , $$\n",
    "which can be seen as the prox of a certain function $\\phi_\\sigma$ (notice that it imposes $\\tau = 1$).\n",
    "\n",
    "Because of the relation between $x_k,z_k$, the objective function on the iterates is\n",
    "$$ \\frac{1}{\\lambda} F(x_k) = \\frac{1}{\\lambda} f(x_k) + g_\\sigma(z_k) - \\frac{1}{2} \\|x_k - z_k\\|^2 .$$\n",
    "\n",
    "Implement this PGD algorithm relying on the proximal denoiser. Along the iterations, track the function values $F(x_k)$, the PSNR and the residual norm $r_k = \\|x_{k}-x_{k-1}\\|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the proximal denoiser\n",
    "D=dinv.models.GSDRUNet(pretrained='ckpts/Prox-DRUNet.ckpt', act_mode='S',train=False).to(device)\n",
    "# # WARNING: be careful when loading the prox-denoiser, which has SoftPlus activation functions.\n",
    "\n",
    "# test it on an image\n",
    "x = y.clone().requires_grad_(True)\n",
    "px = D.potential(x,sigma=nu)\n",
    "grad = torch.autograd.grad(px,x)[0]\n",
    "Dx = x.detach()-grad\n",
    "\n",
    "viewimage(Dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed1033",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D=dinv.models.GSDRUNet(pretrained='ckpts/Prox-DRUNet.ckpt', act_mode='S', train=False).to(device)\n",
    "\n",
    "tau = 2e-4\n",
    "s = 1.8*nu\n",
    "lam = 1e5\n",
    "\n",
    "# initialize\n",
    "xinit = torch.clone(y)\n",
    "xold = xinit.clone().requires_grad_(True)\n",
    "normxinit = torch.linalg.vector_norm(xinit)\n",
    "\n",
    "losstab = []\n",
    "psnrtab = []\n",
    "rtab = []\n",
    "\n",
    "niter = 100\n",
    "t0 = time.time()\n",
    "print('[%4d/%4d] [%.5f s] PSNR = %.2f'%(0,niter,0,psnr(x0,y)))\n",
    "\n",
    "for it in range(niter):\n",
    "\n",
    "\n",
    "    ### TODO ###\n",
    "\n",
    "    if (it+1)%10==0:\n",
    "        print('[%4d/%4d] [%.5f s] PSNR = %.2f, F(x) = %.6f'%(it+1,niter,time.time()-t0,psnrt,Fxnew.item()))\n",
    "        viewimage(xnew)\n",
    "\n",
    "        \n",
    "plt.plot(losstab)\n",
    "plt.title('F(x_n)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(psnrtab)\n",
    "plt.title('PSNR')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.semilogy(rtab)\n",
    "plt.title('Residual Norm')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# save results\n",
    "x_proxpgd = x.detach().clone()\n",
    "losstab_proxpgd = losstab.copy()\n",
    "psnrtab_proxpgd = psnrtab.copy()\n",
    "rtab_proxpgd = rtab.copy()\n",
    "\n",
    "# # save results\n",
    "# tmp_x_proxpgd = x.detach().clone()\n",
    "# tmp_losstab_proxpgd = losstab.copy()\n",
    "# tmp_psnrtab_proxpgd = psnrtab.copy()\n",
    "# tmp_rtab_proxpgd = rtab.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d78ae4",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faebc8f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare the results obtained with the various algorithms implemented above.\n",
    "\n",
    "d = 20\n",
    "ind = np.arange(d,niter)\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.semilogy(ind,losstab_gsgd[d:],label='GSGD')\n",
    "plt.semilogy(ind,losstab_gspgd[d:],label='GSPGD')\n",
    "plt.semilogy(ind,losstab_proxpgd[d:],label='ProxPGD')\n",
    "plt.semilogy(ind,losstab_pgd[d:],label='PGD')\n",
    "# plt.semilogy(ind,losstab_gspgd2[d:],label='GSPGD2')\n",
    "plt.title('F(x_n)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.plot(ind,psnrtab_gsgd,label='GSGD')\n",
    "plt.plot(ind,psnrtab_gspgd,label='GSPGD')\n",
    "plt.plot(ind,psnrtab_proxpgd,label='ProxPGD')\n",
    "plt.plot(ind,psnrtab_pgd,label='PGD')\n",
    "# plt.plot(psnrtab_gspgd2,label='GSPGD2')\n",
    "plt.title('PSNR')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.semilogy(ind,rtab_gsgd[d:],label='GSGD')\n",
    "plt.semilogy(ind,rtab_gspgd[d:],label='GSPGD')\n",
    "plt.semilogy(ind,rtab_proxpgd[d:],label='ProxPGD')\n",
    "plt.semilogy(ind,rtab_pgd[d:],label='PGD')\n",
    "# plt.semilogy(ind,rtab_gspgd2[d:],label='GSPGD2')\n",
    "plt.title('Residual Norm')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ecf6e3",
   "metadata": {},
   "source": [
    "## Baseline Comparisons with explicit regularizations (Tychonov or SmoothTV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f034f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Deblurring with Tychonov Regularization\n",
    "def tych_deblur(y,k,lam=0.01):\n",
    "    _,_,M,N = y.shape\n",
    "    xi = torch.arange(M)\n",
    "    ind = (xi>M/2)\n",
    "    xi[ind] = xi[ind]-M\n",
    "    zeta = torch.arange(N)\n",
    "    ind = (zeta>N/2)\n",
    "    zeta[ind] = zeta[ind]-N\n",
    "    Xi,Zeta = torch.meshgrid(xi,zeta,indexing='ij')\n",
    "    Xi = Xi[None,None,:,:].to(device)\n",
    "    Zeta = Zeta[None,None,:,:].to(device)\n",
    "    fh = torch.conj(fk)/(torch.abs(fk)**2 + 8 * lam * (torch.sin(pi*Xi/M)**2 + torch.sin(pi*Zeta/N)**2))\n",
    "    return ifft2(fft2(y)*fh).real\n",
    "\n",
    "xtych = tych_deblur(y,k)\n",
    "\n",
    "# Smooth TV regularization\n",
    "def stv_deblur(A,y,xinit,niter=1000,lam=0.002,ep=0.01,lr=None):\n",
    "    if lr is None:\n",
    "        lr = 1.9/(1+lam*8/ep)\n",
    "    x = xinit.clone().requires_grad_(True)\n",
    "    optim = torch.optim.SGD([x], lr=lr)\n",
    "    losslist = []\n",
    "    for it in range(niter):\n",
    "        d1 = torch.roll(x,-1,2) - x\n",
    "        d2 = torch.roll(x,-1,3) - x\n",
    "        reg = torch.sum(torch.sqrt(ep**2+d1**2+d2**2))\n",
    "        loss = torch.sum((A(x)-y)**2) + lam*reg\n",
    "        losslist.append(loss.item())\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    return x.detach(),losslist\n",
    "\n",
    "xtv,_ = stv_deblur(A,y,y.clone())\n",
    "\n",
    "# # Display the results\n",
    "# print('PSNR(x0,xtych) = %.2f'%psnr(x0,xtych))\n",
    "# viewimage(xtych)\n",
    "# print('PSNR(x0,xtv) = %.2f'%psnr(x0,xtv))\n",
    "# viewimage(xtv)\n",
    "\n",
    "plt.figure(dpi=180)\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(tensor2im(x0), cmap='gray')\n",
    "plt.title('Original',fontsize=8)\n",
    "# plt.imshow(tensor2im(y), cmap='gray')\n",
    "# plt.title('Degraded \\n PSNR='+str2(psnr(x0,y)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(tensor2im(xtych), cmap='gray')\n",
    "plt.title('Tychonov \\n PSNR='+str2(psnr(x0,xtych)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(tensor2im(xtv), cmap='gray')\n",
    "plt.title('SmoothTV \\n PSNR='+str2(psnr(x0,xtv)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(tensor2im(x_gspgd), cmap='gray')\n",
    "plt.title('PnP-PGD \\n PSNR='+str2(psnr(x0,x_gspgd)),fontsize=8)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8c1d7",
   "metadata": {},
   "source": [
    "<br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e1d06",
   "metadata": {},
   "source": [
    "# Exercice 2: Image Super-resolution\n",
    "\n",
    "<br/><br/>\n",
    "Use your favorite plug-and-play algorithm to tackle image super-resolution in a stable way.\n",
    "\n",
    "The direct model $Ax = (k*x)_{\\downarrow p}$ is a composition of an anti-aliasing filter (e.g. Butterworth filter, see below) with a downsampling step with stride $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ca995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the framework to address super-resolution with smoothed TV\n",
    "# For anti-aliasing, you may use the Butterworth filter of order n and cut-off frequency fc \n",
    "#   given below\n",
    "\n",
    "# fc is the cut-off frequency normalized in (0,1)\n",
    "def butterworth(M,N,fc=.5,order=5):\n",
    "    xi = torch.arange(M)\n",
    "    ind = (xi>M/2)\n",
    "    xi[ind] = xi[ind]-M\n",
    "    zeta = torch.arange(N)\n",
    "    ind = (zeta>N/2)\n",
    "    zeta[ind] = zeta[ind]-N\n",
    "    Xi,Zeta = torch.meshgrid(xi,zeta,indexing='ij')\n",
    "    Xi = Xi[None,None,:,:].to(device)\n",
    "    Zeta = Zeta[None,None,:,:].to(device)\n",
    "    bf1 = 1/torch.sqrt(1+(Xi/(M*fc/2))**(2*order))\n",
    "    bf2 = 1/torch.sqrt(1+(Zeta/(N*fc/2))**(2*order))\n",
    "    return bf1*bf2\n",
    "    \n",
    "bf = butterworth(M,N)\n",
    "viewimage(bf)\n",
    "\n",
    "# Use example:\n",
    "bf = butterworth(x0.shape[2],x0.shape[3],fc=.5)\n",
    "x0f = ifft2(bf*fft2(x0)).real\n",
    "\n",
    "viewimage(x0)\n",
    "viewimage(x0f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
