{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486ac486",
   "metadata": {},
   "source": [
    "# Learning GAN and WGAN for a synthetic 2-dimensional dataset\n",
    "\n",
    "<br/><br/>\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/generativemodelingmva/generativemodelingmva.github.io/blob/main/tp2425/tp3_generative_networks.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09816bf",
   "metadata": {},
   "source": [
    "This practical session contains\n",
    "- \"QUESTION\" fields in the text\n",
    "- blocks of code that you should complete at every region marked with ### ... ###\n",
    "\n",
    "We advise you to open the notebooks on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745878b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1127a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    dtype = torch.FloatTensor\n",
    "\n",
    "# If you don't want to bother with the device, stay on cpu:\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c8f5f7",
   "metadata": {},
   "source": [
    "### Target Measure\n",
    "\n",
    "In the following cell, we define the discrete target measure $\\nu$ that will serve as dataset for this practical session.\n",
    "\n",
    "The variable `xgrid` contains a grid of points that will be useful below to display the discriminators along training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff21cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2   # dimension of the data points\n",
    "n = 6   # number of data points\n",
    "\n",
    "y = torch.zeros((n,d), device=device)\n",
    "y[0, 0] = 0.9\n",
    "y[0, 1] = 0.2\n",
    "\n",
    "y[1, 0] = 0.75\n",
    "y[1, 1] = 0.8\n",
    "\n",
    "y[2, 0] = 0.3\n",
    "y[2, 1] = 0.4\n",
    "\n",
    "y[3, 0] = 0.4\n",
    "y[3, 1] = 0.7\n",
    "\n",
    "y[4, 0] = 0.45\n",
    "y[4, 1] = 0.75\n",
    "\n",
    "y[5, 0] = 0.7\n",
    "y[5, 1] = 0.5\n",
    "\n",
    "nu = torch.ones(n, device=device)/n  # equal masses (nu is the empirical measure of the data)\n",
    "\n",
    "# generate grid for plotting purpose\n",
    "nr,nc = 256,256\n",
    "extent = ((-0.5/nc, 1-0.5/nc, 1-0.5/nr, -0.5/nr))\n",
    "xs = torch.linspace(0, 1, steps=nr)\n",
    "ys = torch.linspace(0, 1, steps=nc)\n",
    "xm, ym = torch.meshgrid(xs, ys, indexing='ij')\n",
    "xm = xm.T\n",
    "ym = ym.T\n",
    "xgrid = torch.cat((xm.reshape(nr*nc,1),ym.reshape(nr*nc,1)),1).to(device)\n",
    "\n",
    "# Plot data points\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(np.zeros((nr,nc)),cmap = 'Oranges', extent=extent) # background\n",
    "plt.scatter(y[:, 0].cpu(), y[:,1].cpu(),c='navy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7252b7bb",
   "metadata": {},
   "source": [
    "## Define Generator architecture\n",
    "\n",
    "QUESTION: Examine the layers and parameters of the following generative network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module): \n",
    "    \n",
    "    def __init__(self, n_in, n_out, n_hid=10, nlayers=3, device=torch.device(\"cpu\")):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        self.n_hid = n_hid\n",
    "        self.nlayers = nlayers\n",
    "        self.hidden = nn.ModuleList()\n",
    "        \n",
    "        for n in range(nlayers):\n",
    "            n_in_t = n_in if n==0 else n_hid\n",
    "            self.hidden.append(nn.Sequential(\n",
    "            nn.Linear(n_in_t, n_hid),\n",
    "            nn.ELU(1)\n",
    "        ).to(device))\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(n_hid, n_out),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        for n in range(self.nlayers):\n",
    "            x = self.hidden[n](x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight, 1.0)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b16a0f",
   "metadata": {},
   "source": [
    "QUESTION: Plot one initial configuration of the generator (draw a batch of generated points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5c34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)  # initialize random seed for reproducibility\n",
    "\n",
    "n_in = 10    # dimension of the input noise\n",
    "b = 100      # batch size\n",
    "\n",
    "# Initialize generator\n",
    "G = Generator(n_in=n_in, n_out=d, n_hid=100, nlayers=3, device=device)\n",
    "\n",
    "# Draw a batch x of generated points\n",
    "#    Input noise z : standard normal with shape (b, n_in)\n",
    "\n",
    "### ... ###\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "xd = x.detach()\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(np.zeros((nr,nc)),cmap = 'Oranges', extent=extent) # background\n",
    "plt.scatter(xd[:, 0].cpu(), xd[:,1].cpu(),c='deepskyblue',alpha=.5)\n",
    "plt.scatter(y[:, 0].cpu(), y[:,1].cpu(),c='navy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ea2eb5",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5722cf",
   "metadata": {},
   "source": [
    "# Exercise 1: WGAN Learning\n",
    "\n",
    "## Discriminator Architecture\n",
    "\n",
    "QUESTION: Examine the layers and parameters of the following discriminative network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b7da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWGAN(nn.Module):\n",
    "  def __init__(self, n_in, n_hid=10):\n",
    "    super(DWGAN, self).__init__()\n",
    "\n",
    "    self.n_hid = n_hid\n",
    "    self.n_in = n_in\n",
    "\n",
    "    self.fc1 = nn.Linear(n_in, n_hid)\n",
    "    self.fc2 = nn.Linear(n_hid, n_hid)\n",
    "    self.fc3 = nn.Linear(n_hid, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    y = nn.LeakyReLU(negative_slope=0.2)(self.fc1(x))\n",
    "    y = nn.LeakyReLU(negative_slope=0.2)(self.fc2(y))\n",
    "    y = self.fc3(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f13622",
   "metadata": {},
   "source": [
    "## Weight clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed78b86",
   "metadata": {},
   "source": [
    "QUESTION: For a fixed generator, train the discriminator with WGAN loss and weight clipping. \n",
    "\n",
    "Try changing the clip_value. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224ab56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)  # initialize random seed for reproducibility\n",
    "\n",
    "# fix one generator\n",
    "G = Generator(n_in=n_in, n_out=d, n_hid=10, nlayers=3, device=device)\n",
    "\n",
    "# parameters for discriminator optimization\n",
    "lrdisc = 0.002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "niterD=1000\n",
    "\n",
    "clip_value = .1\n",
    "\n",
    "D = DWGAN(n_in=d, n_hid=10).to(device)\n",
    "optimD = optim.Adam(D.parameters(), lr=lrdisc, betas=(beta_1, beta_2))\n",
    "\n",
    "iter_display = 100  # display current configuration each iter_display iteration\n",
    "\n",
    "# Lists to keep track of progress\n",
    "Dlosses = []\n",
    "    \n",
    "for iter in range(0,niterD):\n",
    "\n",
    "    ### UPDATE OF D ###\n",
    "    ### ... (optim of D) ... ###\n",
    "    ### ... (weight clipping step) ... ### \n",
    "\n",
    "    ### SAVE LOSS ###\n",
    "    Dlosst = Dloss.item()\n",
    "    Dlosses.append(-Dlosst)\n",
    "\n",
    "    if(iter%iter_display == 0):\n",
    "        print('[%d/%d], %f' % (iter, niterD, Dlosst))\n",
    "        Dxgrid = D(xgrid).detach().cpu().numpy().reshape(nr,nc)\n",
    "        x = G(z) \n",
    "        xd = x.detach().squeeze(1)\n",
    "        strtitle = 'Iter '+str(iter)\n",
    "        fig = plt.figure(dpi=100)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(Dxgrid,cmap = 'Oranges', extent=extent)  # discriminator\n",
    "        plt.scatter(xd[:, 0].cpu(), xd[:,1].cpu(),c='deepskyblue',alpha=.5)\n",
    "        plt.scatter(y[:, 0].cpu(), y[:,1].cpu(),c='navy')\n",
    "        plt.title(strtitle)\n",
    "        plt.show()\n",
    "\n",
    "plt.plot(Dlosses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a4083c",
   "metadata": {},
   "source": [
    "QUESTION: Now, train both the generator and discriminator with the WGAN loss and weight clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611c1d32",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 0.002   # learning rate for generator\n",
    "\n",
    "## parameters for training\n",
    "n_epochs = 100\n",
    "niterD=1000\n",
    "niterG=10\n",
    "\n",
    "torch.manual_seed(1)  # initialize random seed for reproducibility\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "### ... ###\n",
    "\n",
    "optimG = optim.Adam(G.parameters(), lr=lr)\n",
    "optimD = optim.Adam(D.parameters(), lr=lrdisc, betas=(beta_1, beta_2))\n",
    "\n",
    "\n",
    "Glosses = []\n",
    "Dlosses = []\n",
    "\n",
    "clip_value = .1\n",
    "iter_display = 10\n",
    "\n",
    "# Main loop\n",
    "for epoch in range(1,n_epochs):\n",
    "    \n",
    "    ############################\n",
    "    ### Train discriminator (niterD iterations)\n",
    "    ############################\n",
    "    for iter in range(0,niterD):\n",
    "        ### ... ###\n",
    "      \n",
    "    ############################\n",
    "    ### Train generator (niterG iterations)\n",
    "    ############################\n",
    "    for iter in range(0,niterG):\n",
    "        ### ... ###\n",
    "\n",
    "\n",
    "    # Output training stats\n",
    "    print('[%d/%d] \\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "      % (epoch, n_epochs, Dloss.item(), Gloss.item()))\n",
    "    Glosses.append(Gloss.item())\n",
    "    Dlosses.append(Dloss.item())\n",
    "\n",
    "    if(epoch % iter_display == 0):\n",
    "        Dxgrid = D(xgrid).detach().cpu().numpy().reshape(nr,nc)\n",
    "        z = torch.randn(b, n_in, device=device)\n",
    "        x = G(z) \n",
    "        xd = x.detach().squeeze(1)\n",
    "        strtitle = 'Epoch '+str(epoch)\n",
    "        fig = plt.figure(dpi=100)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(Dxgrid,cmap = 'Oranges', extent=extent)\n",
    "        plt.scatter(xd[:, 0].cpu(), xd[:,1].cpu(),c='deepskyblue',alpha=.5)\n",
    "        plt.scatter(y[:, 0].cpu(), y[:,1].cpu(),c='navy')\n",
    "        plt.title(strtitle)\n",
    "        plt.show()\n",
    "       \n",
    "    \n",
    "### Plot the evolution of the discriminator and generator losses ###\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(Dlosses,label='D')\n",
    "plt.plot(Glosses,label='G')\n",
    "plt.title('Loss evolution')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Save final generator for later use\n",
    "wganwc = Generator(n_in=n_in, n_out=d, n_hid=10, nlayers=3, device=device)\n",
    "wganwc.load_state_dict(G.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053612e0",
   "metadata": {},
   "source": [
    "## Estimate the Lipschitz constant of the discriminator\n",
    "\n",
    "QUESTION: Implement a function computing an estimation of the Lipschitz constant of $D$ on points that are interpolated between $x$ and $y$.\n",
    "\n",
    "Use this function to examine the Lipschitz constant of the final discriminator obtained with WGAN-WC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0374ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lipconstant(D,x,y):\n",
    "    # Calculate interpolation\n",
    "    b = x.shape[0]\n",
    "    n = y.shape[0]\n",
    "    alpha = torch.rand((b,n,1),device=device)\n",
    "    interp = (alpha * y[None,:,:] + (1 - alpha) * x[:,None,:]).flatten(end_dim=1)\n",
    "    interp.requires_grad_()\n",
    "\n",
    "    # Calculate discriminator on interpolated examples\n",
    "    Di = ### ... ###\n",
    "\n",
    "    # Calculate gradients of probabilities with respect to examples\n",
    "    gradients = ### ... ###\n",
    "\n",
    "    # Derivatives of the gradient close to 0 can cause problems because of\n",
    "    # the square root, so manually calculate norm and add epsilon\n",
    "    gradients_norm = ### ... ###\n",
    "\n",
    "    # Return gradient penalty\n",
    "    return ### ... ###\n",
    "\n",
    "#### (lip constant of the current D) ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6af58",
   "metadata": {},
   "source": [
    "## Gradient Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf63e3",
   "metadata": {},
   "source": [
    "QUESTION: Implement a function computing the gradient penalty of $D$ on points that are interpolated between $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055df621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(D,x,y):\n",
    "    # Calculate interpolation\n",
    "    b = x.shape[0]\n",
    "    n = y.shape[0]\n",
    "    alpha = torch.rand((b,n,1),device=device)\n",
    "    interp = (alpha * y[None,:,:] + (1 - alpha) * x[:,None,:]).flatten(end_dim=1)\n",
    "    interp.requires_grad_()\n",
    "\n",
    "    #### ... ###\n",
    "    \n",
    "    # Return gradient penalty    \n",
    "    #### ... ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d104c",
   "metadata": {},
   "source": [
    "## Train the WGAN-GP discriminator for a fixed generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24068817",
   "metadata": {},
   "source": [
    "QUESTION: Complete the following code at the blocks ###...###. \n",
    "\n",
    "Adjust the weight of the gradient penalty (parameter `gpw`) to get a Lipschitz constant $\\leq 1$.\n",
    "\n",
    "How would you judge the resulting discriminator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e4b289",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)  # initialize random seed for reproducibility\n",
    "\n",
    "# Reinitialize generators and discriminators\n",
    "#### ... ###\n",
    "\n",
    "optimG = optim.Adam(G.parameters(), lr=lr)\n",
    "optimD = optim.Adam(D.parameters(), lr=lrdisc, betas=(beta_1, beta_2))\n",
    "\n",
    "# parameters for discriminator optimization\n",
    "lrdisc = 0.002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "gpw = 1\n",
    "niterD=1000\n",
    "\n",
    "iter_display = 100  # display current configuration each iter_display iteration\n",
    "\n",
    "# Lists to keep track of progress\n",
    "Dlosses = []\n",
    "    \n",
    "for iter in range(0,niterD):\n",
    "\n",
    "    #### ... ###\n",
    "    # (adapt the loop written for WGAN-WC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final estimated Lipschitz constant = ',lipconstant(D,x,y).item())\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(Dlosses)\n",
    "plt.title('Discriminator loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389de26d",
   "metadata": {},
   "source": [
    "## Train both the Generator and Discriminator\n",
    "\n",
    "QUESTION: Learn both generator and discriminator with the gradient penalty term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ab2de9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 0.002   # learning rate for generator\n",
    "\n",
    "## parameters for training\n",
    "n_epochs = 100\n",
    "niterD=1000\n",
    "niterG=10\n",
    "\n",
    "lrdisc = 0.002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "gpw = 0.1\n",
    "niterD=100\n",
    "\n",
    "torch.manual_seed(1)  # initialize random seed for reproducibility\n",
    "\n",
    "# Initialize generators and discriminators\n",
    "G = Generator(n_in=n_in, n_out=d, n_hid=10, nlayers=3, device=device)\n",
    "optimG = optim.Adam(G.parameters(), lr=lr)\n",
    "\n",
    "D = DWGAN(n_in=d, n_hid=10).to(device)\n",
    "optimD = optim.Adam(D.parameters(), lr=lrdisc, betas=(beta_1, beta_2))\n",
    "\n",
    "\n",
    "Glosses = []\n",
    "Dlosses = []\n",
    "\n",
    "iter_display = 5\n",
    "\n",
    "#### ... ###\n",
    "# (adapt the loop written for WGAN-WC)\n",
    "       \n",
    "    \n",
    "# Save final generator for later use\n",
    "wgan = Generator(n_in=n_in, n_out=d, n_hid=10, nlayers=3, device=device)\n",
    "wgan.load_state_dict(G.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a8b1ad",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5625a",
   "metadata": {},
   "source": [
    "# Exercise 2: Learn a GAN \n",
    "\n",
    "## Define Discriminator Architecture\n",
    "\n",
    "QUESTION: What do you have to change to get a discriminator adapted for GAN training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d51ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGAN(nn.Module):\n",
    "  def __init__(self, n_in, n_hid=10):\n",
    "    super(DGAN, self).__init__()\n",
    "\n",
    "    self.n_hid = n_hid\n",
    "    self.n_in = n_in\n",
    "\n",
    "    self.fc1 = nn.Linear(n_in, n_hid)\n",
    "    self.fc2 = nn.Linear(n_hid, n_hid)\n",
    "    self.fc3 = nn.Linear(n_hid, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    y = nn.LeakyReLU(negative_slope=0.2)(self.fc1(x))\n",
    "    y = nn.LeakyReLU(negative_slope=0.2)(self.fc2(y))\n",
    "    y = nn.Sigmoid()(self.fc3(y))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79769efe",
   "metadata": {},
   "source": [
    "## Train the discriminator for a fixed generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23bc401",
   "metadata": {},
   "source": [
    "QUESTION: Complete the following code at the blocks ###...###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1c46c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)  # initialize random seed for reproducibility\n",
    "\n",
    "# parameters for discriminator optimization\n",
    "lrdisc = 0.002\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "niterD=1000\n",
    "\n",
    "D = DGAN(n_in=d, n_hid=10).to(device)\n",
    "optimD = optim.Adam(D.parameters(), lr=lrdisc, betas=(beta_1, beta_2))\n",
    "\n",
    "iter_display = 100  # display current configuration each iter_display iteration\n",
    "\n",
    "# Lists to keep track of progress\n",
    "Dlosses = []\n",
    "   \n",
    "for iter in range(0,niterD):\n",
    "\n",
    "    ### UPDATE OF D ###\n",
    "    optimD.zero_grad()\n",
    "    ### ... ###\n",
    "    Dloss = ### ... ###\n",
    "    Dloss.backward()\n",
    "    optimD.step()\n",
    "\n",
    "    ### SAVE LOSS ###\n",
    "    Dlosst = Dloss.item()\n",
    "    Dlosses.append(-Dlosst)\n",
    "\n",
    "    if(iter%iter_display == 0):\n",
    "        print('[%d/%d], %f' % (iter, niterD, Dlosst))\n",
    "        Dxgrid = D(xgrid).detach().cpu().numpy().reshape(nr,nc)\n",
    "        x = G(z) \n",
    "        xd = x.detach().squeeze(1)\n",
    "        strtitle = 'Iter '+str(iter)\n",
    "        fig = plt.figure(dpi=100)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(Dxgrid,cmap = 'Oranges', extent=extent)  # discriminator\n",
    "        plt.scatter(xd[:, 0].cpu(), xd[:,1].cpu(),c='deepskyblue',alpha=.5)\n",
    "        plt.scatter(y[:, 0].cpu(), y[:,1].cpu(),c='navy')\n",
    "        plt.title(strtitle)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the evolution of the discriminator loss ###\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(Dlosses)\n",
    "plt.title('Discriminator loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c2430",
   "metadata": {},
   "source": [
    "## Train both the Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6191edba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = 0.002   # learning rate for generator\n",
    "\n",
    "## parameters for training\n",
    "n_epochs = 100\n",
    "niterD=1000\n",
    "niterG=10\n",
    "\n",
    "torch.manual_seed(1)  # initialize random seed for reproducibility\n",
    "\n",
    "# Initialize generators and discriminators\n",
    "### ... ###\n",
    "\n",
    "Glosses = []\n",
    "Dlosses = []\n",
    "\n",
    "iter_display = 10\n",
    "\n",
    "# Main loop\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    ############################\n",
    "    ### Train discriminator (niterD iterations)\n",
    "    ############################\n",
    "    for iter in range(0,niterD):\n",
    "        ### ... ###\n",
    "      \n",
    "    ############################\n",
    "    ### Train generator (niterG iterations)\n",
    "    ############################\n",
    "    for iter in range(0,niterG):\n",
    "        ### ... ###\n",
    "\n",
    "    # Output training stats\n",
    "    print('[%d/%d] \\tLoss_D: %.4f\\tLoss_G: %.4f'\n",
    "      % (epoch, n_epochs, Dloss.item(), Gloss.item()))\n",
    "    Glosses.append(Gloss.item())\n",
    "    Dlosses.append(-Dloss.item())\n",
    "\n",
    "\n",
    "    if(epoch % iter_display == 0):\n",
    "        Dxgrid = D(xgrid).detach().cpu().numpy().reshape(nr,nc)\n",
    "        z = torch.randn(b, 1, n_in, device=device)\n",
    "        x = G(z) \n",
    "        xd = x.detach().squeeze(1)\n",
    "        strtitle = 'Epoch '+str(epoch)\n",
    "        fig = plt.figure(dpi=100)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(Dxgrid,cmap = 'Oranges', extent=extent)  # discriminator\n",
    "        plt.scatter(xd[:, 0].cpu(), xd[:,1].cpu(),c='deepskyblue',alpha=.5)\n",
    "        plt.scatter(y[:, 0].cpu(), y[:,1].cpu(),c='navy')\n",
    "        plt.title(strtitle)\n",
    "        plt.show()\n",
    "        \n",
    "# Save final generator for later use\n",
    "gan = Generator(n_in=n_in, n_out=d, n_hid=10, nlayers=3, device=device)\n",
    "gan.load_state_dict(G.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b924dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the evolution of the discriminator and generator losses ###\n",
    "\n",
    "plt.figure(dpi=100)\n",
    "plt.plot(Dlosses,label='D')\n",
    "plt.plot(Glosses,label='G')\n",
    "plt.title('Loss evolution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bca255",
   "metadata": {},
   "source": [
    "## Train the generator only\n",
    "\n",
    "QUESTION: For a fixed discriminator, optimize only the generator only. Can you explain what is happening then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdedb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ... ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d8deb1",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
